{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled8.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "metadata": {
      "interpreter": {
        "hash": "434fba307fd1171c9cfc17821a2afcf8929f30379beeaab9e3fdf8c6db2d1c93"
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "SEyijgUizsOG",
        "outputId": "d9ce2a35-bc35-4450-cd48-b73d2ffc2e2b"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('zoo/german_data.csv', index_col=0)\n",
        "df.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Age     Sex  Job Housing Saving accounts Checking account  Credit amount  \\\n",
              "0   67    male    2     own             NaN           little           1169   \n",
              "1   22  female    2     own          little         moderate           5951   \n",
              "2   49    male    1     own          little              NaN           2096   \n",
              "3   45    male    2    free          little           little           7882   \n",
              "4   53    male    2    free          little           little           4870   \n",
              "\n",
              "   Duration              Purpose  Risk  \n",
              "0         6             radio/TV  good  \n",
              "1        48             radio/TV   bad  \n",
              "2        12            education  good  \n",
              "3        42  furniture/equipment  good  \n",
              "4        24                  car   bad  "
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>Sex</th>\n      <th>Job</th>\n      <th>Housing</th>\n      <th>Saving accounts</th>\n      <th>Checking account</th>\n      <th>Credit amount</th>\n      <th>Duration</th>\n      <th>Purpose</th>\n      <th>Risk</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>67</td>\n      <td>male</td>\n      <td>2</td>\n      <td>own</td>\n      <td>NaN</td>\n      <td>little</td>\n      <td>1169</td>\n      <td>6</td>\n      <td>radio/TV</td>\n      <td>good</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>22</td>\n      <td>female</td>\n      <td>2</td>\n      <td>own</td>\n      <td>little</td>\n      <td>moderate</td>\n      <td>5951</td>\n      <td>48</td>\n      <td>radio/TV</td>\n      <td>bad</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>49</td>\n      <td>male</td>\n      <td>1</td>\n      <td>own</td>\n      <td>little</td>\n      <td>NaN</td>\n      <td>2096</td>\n      <td>12</td>\n      <td>education</td>\n      <td>good</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>45</td>\n      <td>male</td>\n      <td>2</td>\n      <td>free</td>\n      <td>little</td>\n      <td>little</td>\n      <td>7882</td>\n      <td>42</td>\n      <td>furniture/equipment</td>\n      <td>good</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>53</td>\n      <td>male</td>\n      <td>2</td>\n      <td>free</td>\n      <td>little</td>\n      <td>little</td>\n      <td>4870</td>\n      <td>24</td>\n      <td>car</td>\n      <td>bad</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "2p9JZdEwSQaa",
        "outputId": "f9c7d458-9986-47e3-fdad-0955fe4e0831"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               Age          Job  Credit amount     Duration\n",
              "count  1000.000000  1000.000000    1000.000000  1000.000000\n",
              "mean     35.546000     1.904000    3271.258000    20.903000\n",
              "std      11.375469     0.653614    2822.736876    12.058814\n",
              "min      19.000000     0.000000     250.000000     4.000000\n",
              "25%      27.000000     2.000000    1365.500000    12.000000\n",
              "50%      33.000000     2.000000    2319.500000    18.000000\n",
              "75%      42.000000     2.000000    3972.250000    24.000000\n",
              "max      75.000000     3.000000   18424.000000    72.000000"
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>Job</th>\n      <th>Credit amount</th>\n      <th>Duration</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n      <td>1000.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>35.546000</td>\n      <td>1.904000</td>\n      <td>3271.258000</td>\n      <td>20.903000</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>11.375469</td>\n      <td>0.653614</td>\n      <td>2822.736876</td>\n      <td>12.058814</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>19.000000</td>\n      <td>0.000000</td>\n      <td>250.000000</td>\n      <td>4.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>27.000000</td>\n      <td>2.000000</td>\n      <td>1365.500000</td>\n      <td>12.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>33.000000</td>\n      <td>2.000000</td>\n      <td>2319.500000</td>\n      <td>18.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>42.000000</td>\n      <td>2.000000</td>\n      <td>3972.250000</td>\n      <td>24.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>75.000000</td>\n      <td>3.000000</td>\n      <td>18424.000000</td>\n      <td>72.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "2202uIKESTrM",
        "outputId": "a778d840-dcb4-4bf1-97a0-be4d2b5306d6"
      },
      "source": [
        "df.describe(include='O')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Sex Housing Saving accounts Checking account Purpose  Risk\n",
              "count   1000    1000             817              606    1000  1000\n",
              "unique     2       3               4                3       8     2\n",
              "top     male     own          little           little     car  good\n",
              "freq     690     713             603              274     337   700"
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sex</th>\n      <th>Housing</th>\n      <th>Saving accounts</th>\n      <th>Checking account</th>\n      <th>Purpose</th>\n      <th>Risk</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1000</td>\n      <td>1000</td>\n      <td>817</td>\n      <td>606</td>\n      <td>1000</td>\n      <td>1000</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>2</td>\n      <td>3</td>\n      <td>4</td>\n      <td>3</td>\n      <td>8</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>male</td>\n      <td>own</td>\n      <td>little</td>\n      <td>little</td>\n      <td>car</td>\n      <td>good</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>690</td>\n      <td>713</td>\n      <td>603</td>\n      <td>274</td>\n      <td>337</td>\n      <td>700</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5EFqHxB-zEn"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "test_size = 0.20\n",
        "\n",
        "processed_data = None\n",
        "categorical = None\n",
        "label_encoders = {}\n",
        "\n",
        "def preprocessing(data, test_size):\n",
        "    \"\"\"\n",
        "    Preprocess [German](https://raw.githubusercontent.com/humbletechy/Assign/master/datasets_9109_12699_german_credit_data.csv) dataset\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    data: DataFrame\n",
        "        Pandas dataframe containing German dataset.\n",
        "    \"\"\"\n",
        "    \n",
        "    global processed_data\n",
        "    global categorical\n",
        "    global label_encoders\n",
        "\n",
        "    # Drop savings account and checkings account columns as they contain a lot\n",
        "    # of NaN values and may not always be available in real life scenarios\n",
        "    data = data.drop(columns = ['Saving accounts', 'Checking account'])\n",
        "\n",
        "    # print(data.describe())\n",
        "    # print(data.describe(include='O'))\n",
        "\n",
        "    cols = data.columns\n",
        "    num_cols = data._get_numeric_data().columns\n",
        "    categorical = list(set(cols) - set(num_cols))\n",
        "\n",
        "    # Drop null rows\n",
        "    # data = data.dropna()\n",
        "\n",
        "    # Encode text columns to number values\n",
        "    for category in categorical:\n",
        "        le = LabelEncoder()\n",
        "        data[category] = le.fit_transform(data[category])\n",
        "        label_encoders[category] = le\n",
        "\n",
        "    for col in data.columns:\n",
        "        if(col not in categorical):\n",
        "            data[col] = (data[col].astype('float') - np.mean(data[col].astype('float')))/np.std(data[col].astype('float'))\n",
        "\n",
        "    # print(data.describe())\n",
        "    # print(data.describe(include='O'))\n",
        "\n",
        "    processed_data = data\n",
        "\n",
        "    # Get Training parameters\n",
        "    target_col = data.columns[-1]\n",
        "    x = data.drop(columns=target_col, axis=1)\n",
        "    y = data[target_col].astype('int')\n",
        "\n",
        "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = test_size)\n",
        "    x_train = pd.DataFrame(x_train)\n",
        "    y_train = pd.DataFrame(y_train)\n",
        "\n",
        "    sc = StandardScaler()\n",
        "    x_train = sc.fit_transform(x_train)\n",
        "    x_test = sc.transform(x_test)\n",
        "\n",
        "    return (x_train, x_test, y_train, y_test)\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = preprocessing(df, test_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Sex', 'Purpose', 'Housing', 'Risk']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Sex': LabelEncoder(),\n",
              " 'Purpose': LabelEncoder(),\n",
              " 'Housing': LabelEncoder(),\n",
              " 'Risk': LabelEncoder()}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "label_encoders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['zoo/label_encoders.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(categorical, \"zoo/categorical.joblib\", compress=True)\n",
        "joblib.dump(label_encoders, \"zoo/label_encoders.joblib\", compress=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV, ShuffleSplit\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, recall_score, precision_score\n",
        "\n",
        "class Model(object):\n",
        "    \"\"\"\n",
        "    Basic Scorecard Model\n",
        "\n",
        "    Warning: This class should not be used directly. Use derived classes\n",
        "    instead.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 classifier=None,\n",
        "                 test_size=test_size,\n",
        "                 n_splits=1,\n",
        "                 random_state=None,\n",
        "                 n_jobs=None,\n",
        "                 params=None):\n",
        "                 \n",
        "        self.classifier = classifier\n",
        "        self.params = params\n",
        "        self.random_state = random_state\n",
        "        self.test_size = test_size\n",
        "        self.n_splits = n_splits\n",
        "        self.n_jobs = n_jobs\n",
        "\n",
        "        self.model = GridSearchCV(estimator=classifier,\n",
        "                                  param_grid=params,\n",
        "                                  n_jobs=n_jobs,\n",
        "                                  cv=ShuffleSplit(test_size=test_size,\n",
        "                                  n_splits=n_splits,\n",
        "                                  random_state=0))\n",
        "    \n",
        "    def __str__(self):\n",
        "        return f\"\"\"\n",
        "        Model Object\n",
        "        ----------------------------------------------------------------\n",
        "\n",
        "        Classifier: {self.classifier.__class__.__name__}\n",
        "        Test Size: {self.test_size}\n",
        "        Random State: {self.random_state}\n",
        "        Number of Splits: {self.n_splits}\n",
        "        Parameter Grid: {self.params}\n",
        "\n",
        "        {self.model}\n",
        "        \"\"\"\n",
        "    \n",
        "    def __repr__(self):\n",
        "        return self.__str__()\n",
        "\n",
        "    def train(self, x_train, y_train):\n",
        "        \"\"\"\n",
        "        Train scorecard model\n",
        "        \n",
        "        Args:\n",
        "            x_train:\n",
        "                array of training parameters\n",
        "            y_train:\n",
        "                pandas dataframe with training labels\n",
        "        \"\"\"\n",
        "\n",
        "        self.model = self.model.fit(x_train, y_train.values.ravel())\n",
        "        return self\n",
        "\n",
        "    def predict(self, data):\n",
        "        \"\"\"\n",
        "        Predict scorecard model\n",
        "\n",
        "        Args:\n",
        "            data: array\n",
        "                Data to perform prediction on.\n",
        "        \"\"\"\n",
        "\n",
        "        return self.model.predict(data)\n",
        "\n",
        "    def accuracy(self, x_test, y_test):\n",
        "        \"\"\"\n",
        "        Compute scorecard model accuracy\n",
        "\n",
        "        Args:\n",
        "            x_test: array\n",
        "                The test parameters.\n",
        "            y_test: array\n",
        "                The labels\n",
        "        \"\"\"\n",
        "\n",
        "        y_pred = self.predict(x_test)\n",
        "        return accuracy_score(y_test, y_pred, normalize=False)\n",
        "\n",
        "    def metrics(self, x_test, y_test):\n",
        "        \"\"\"\n",
        "        Comput scorecard model metrics\n",
        "        \n",
        "        Args:\n",
        "            x_test: array\n",
        "                The test parameters.\n",
        "            y_test: array\n",
        "                The labels\n",
        "        \"\"\"\n",
        "\n",
        "        y_pred = self.predict(x_test)\n",
        "        \n",
        "        cm = confusion_matrix(y_pred, y_test)\n",
        "        accuracy = accuracy_score(y_test, y_pred, normalize=True)\n",
        "        f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
        "        recall = recall_score(y_test, y_pred, average=\"macro\")\n",
        "        precision = precision_score(y_test, y_pred, average=\"macro\")\n",
        "\n",
        "        return {\"accuracy\" : accuracy,\n",
        "                \"f1_score\" : f1,\n",
        "                \"recall_score\" : recall,\n",
        "                \"precision_score\": precision}\n",
        "\n",
        "class RandomForest(Model):\n",
        "    def __init__(self,\n",
        "                 classifier=RandomForestClassifier(),\n",
        "                 test_size=test_size,\n",
        "                 n_splits=1,\n",
        "                 random_state=0,\n",
        "                 n_jobs=None,\n",
        "                 params={'n_estimators' : [20, 30, 40], 'random_state' : [0]}):        \n",
        "        super(RandomForest, self).__init__(classifier,\n",
        "                                           test_size,\n",
        "                                           n_splits,\n",
        "                                           random_state,\n",
        "                                           n_jobs,\n",
        "                                           params)\n",
        "\n",
        "class SVC(Model):\n",
        "    def __init__(self,\n",
        "                 classifier=SVC(),\n",
        "                 test_size=test_size,\n",
        "                 n_splits=1,\n",
        "                 random_state=0,\n",
        "                 n_jobs=None,\n",
        "                 params={'kernel' : ['poly'], 'degree' : [2, 3, 4]}):\n",
        "        super(SVC, self).__init__(classifier,\n",
        "                                  test_size,\n",
        "                                  n_splits,\n",
        "                                  random_state,\n",
        "                                  n_jobs,\n",
        "                                  params)\n",
        "\n",
        "class MLP(Model):\n",
        "    def __init__(self,\n",
        "                 classifier=MLPClassifier(),\n",
        "                 test_size=test_size,\n",
        "                 n_splits=1,\n",
        "                 random_state=0,\n",
        "                 n_jobs=-1,\n",
        "                 params={'hidden_layer_sizes' : [(100, 50 ,10)],\n",
        "                         'max_iter' : [500],\n",
        "                         'activation' : ['relu'],\n",
        "                         'solver' : ['adam'],\n",
        "                         'random_state' : [1]}):\n",
        "        super(MLP, self).__init__(classifier,\n",
        "                                  test_size,\n",
        "                                  n_splits,\n",
        "                                  random_state,\n",
        "                                  n_jobs,\n",
        "                                  params)\n",
        "\n",
        "class GradientBoost(Model):\n",
        "    def __init__(self,\n",
        "                 classifier=GradientBoostingClassifier(),\n",
        "                 test_size=test_size,\n",
        "                 n_splits=1,\n",
        "                 random_state=0,\n",
        "                 n_jobs=None,\n",
        "                 params={'n_estimators' : [100, 200, 50],\n",
        "                         'random_state' : [0],\n",
        "                         'learning_rate' : [1.0],\n",
        "                         'max_depth' : [1, 2, 3]}):\n",
        "        super(GradientBoost, self).__init__(classifier,\n",
        "                                            test_size,\n",
        "                                            n_splits,\n",
        "                                            random_state,\n",
        "                                            n_jobs,\n",
        "                                            params)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsNPtNSe-2Hz",
        "outputId": "41b2bbba-e1ac-4af9-c2fb-188c033de293"
      },
      "source": [
        "RFmodel = RandomForest()\n",
        "SVCmodel = SVC()\n",
        "MLPmodel = MLP()\n",
        "GBmodel = GradientBoost()"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtMd47u3CjUV"
      },
      "source": [
        "RFmodel = RFmodel.train(x_train, y_train)\n",
        "SVCmodel = SVCmodel.train(x_train, y_train)\n",
        "MLPmodel = MLPmodel.train(x_train, y_train)\n",
        "GBmodel = GBmodel.train(x_train, y_train)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\Kazen\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVrV7Q2bDKfz",
        "outputId": "92c1cf1f-e112-43e6-b82e-e49a2af4e3a7"
      },
      "source": [
        "print(f\"Random Forest: {RFmodel.metrics(x_test, y_test)}\")\n",
        "print(f\"SVM: {SVCmodel.metrics(x_test, y_test)}\")\n",
        "print(f\"MLP: {MLPmodel.metrics(x_test, y_test)}\")\n",
        "print(f\"Gradient Boost: {GBmodel.metrics(x_test, y_test)}\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest: {'accuracy': 0.665, 'f1_score': 0.5503204805530387, 'recall_score': 0.5494417862838916, 'precision_score': 0.5607293550331525}\nSVM: {'accuracy': 0.74, 'f1_score': 0.5393338058114813, 'recall_score': 0.5596859281069808, 'precision_score': 0.734006734006734}\nMLP: {'accuracy': 0.63, 'f1_score': 0.5507527926177757, 'recall_score': 0.5513433934486566, 'precision_score': 0.5503065272268302}\nGradient Boost: {'accuracy': 0.675, 'f1_score': 0.5376791493296347, 'recall_score': 0.5406085142927248, 'precision_score': 0.5586463501063076}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['zoo/gb_classifier.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(RFmodel.model, \"zoo/rf_classifier.joblib\", compress=True)\n",
        "joblib.dump(SVCmodel.model, \"zoo/svc_classifier.joblib\", compress=True)\n",
        "joblib.dump(MLPmodel.model, \"zoo/mlp_classifier.joblib\", compress=True)\n",
        "joblib.dump(GBmodel.model, \"zoo/gb_classifier.joblib\", compress=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ]
}